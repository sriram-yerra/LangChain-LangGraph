{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c15d4503",
   "metadata": {},
   "source": [
    "### **Messages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e6e338d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_93467/3513173221.py:11: DeprecationWarning: Use [`ChatGoogleGenerativeAI`][langchain_google_genai.ChatGoogleGenerativeAI] instead.\n",
      "  llm_vertexAI = ChatVertexAI(\n",
      "/tmp/ipykernel_93467/3513173221.py:11: LangChainDeprecationWarning: The class `ChatVertexAI` was deprecated in LangChain 3.2.0 and will be removed in 4.0.0. An updated version of the class exists in the `langchain-google-genai package and should be used instead. To use it run `pip install -U `langchain-google-genai` and import as `from `langchain_google_genai import ChatGoogleGenerativeAI``.\n",
      "  llm_vertexAI = ChatVertexAI(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OMG, did you know that a group of pugs is called a \"grumble\"? Like, can you even imagine a whole squad of pugs just grumbling around? I'm dead! ðŸ˜‚\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load env variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_google_vertexai import ChatVertexAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Gemini (Vertex AI) using env vars\n",
    "llm_vertexAI = ChatVertexAI(\n",
    "    model_name=os.getenv(\"GEMINI_MODEL\"),\n",
    "    temperature=float(os.getenv(\"TEMPERATURE\")),\n",
    "    project=os.getenv(\"GOOGLE_CLOUD_PROJECT\"),\n",
    "    location=os.getenv(\"GOOGLE_CLOUD_REGION\"),\n",
    "    max_output_tokens=int(os.getenv(\"MAX_OUTPUT_TOKENS\"))\n",
    ")\n",
    "\n",
    "# Messages\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a Gen-Z assistant who answers in a fun way\"),\n",
    "    HumanMessage(content=\"Bro..! Tell me a fun fact\")\n",
    "]\n",
    "\n",
    "# Invoke\n",
    "response = llm_vertexAI.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c721ed85",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e57aab78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a fun fact about flowers:\n",
      "\n",
      "**Did you know that chocolate comes from the flower of the cacao tree?** The cacao tree produces small, delicate flowers directly on its trunk and branches, and it's from these flowers that the pods containing the cocoa beans are grown!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "user_input = input(\"Enter a topic for fun fact: \")\n",
    "\n",
    "dynamic_prompt = PromptTemplate.from_template(\n",
    "    \"Write a fun fact about {topic}\"\n",
    ")\n",
    "\n",
    "ready_prompt = dynamic_prompt.invoke({\"topic\": user_input})\n",
    "\n",
    "response = llm_vertexAI.invoke(ready_prompt)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b68bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a fun assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='Write a fun fact about king', additional_kwargs={}, response_metadata={})]\n",
      "Alright, buckle up for this royal revelation!\n",
      "\n",
      "Did you know that King Henry VIII of England had a GROOM OF THE STOOL? Yep, you read that right. This wasn't just some guy who cleaned the royal toilet. The Groom of the Stool was a high-ranking courtier, often from a noble family, who was in charge of assisting the king with his... ahem... *bathroom needs*. Because of this intimate access, the Groom of the Stool often became a close confidant and advisor to the king, wielding significant political influence!\n",
      "\n",
      "So, next time you're feeling down about your job, remember, at least you're not the Groom of the Stool! ðŸ‘‘ðŸš½ðŸ˜‚\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a {tone} assistant\"),\n",
    "    (\"user\", \"Write a fun fact about {topic}\")\n",
    "])\n",
    "\n",
    "user_input = input(\"Enter topic: \")\n",
    "user_tone = input(\"Enter tone: \")\n",
    "\n",
    "ready_prompt = prompt_template.invoke({\n",
    "    \"topic\": user_input,\n",
    "    \"tone\": user_tone\n",
    "})\n",
    "\n",
    "response = llm_vertexAI.invoke(ready_prompt.messages)\n",
    "\n",
    "# print(ready_prompt)\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
